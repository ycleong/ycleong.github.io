[{"authors":["admin"],"categories":null,"content":"I will be starting as an Assistant Professor at the Department of Psychology at the University of Chicago in July 2021. I am looking to hire a lab manager to start with me. For more information, please see this ad. (Update 4/19/21: We have begun shortlisting candidates, and would not encourage new applications at this time. If you are halfway through putting in an application, please send it in as soon as possible).\nFor undergraduates at the University of Chicago interested in research assistant opportunities, please see this handout.\nImagine playing a heated tennis match and hitting a shot that might or might not have just grazed the sidelines. Would your motivation to win make you more likely to see the ball as having stayed within bounds? Most of us can think of times when we or people we know were biased to see what is desirable, rather than what is really there. How does this happen, and what can we do about it?\nMy research examines the different ways in which goals, desires and needs affect how people perceive and respond to our environment. My work draws from the traditions of cognitive neuroscience, social psychology and affective science. I use a broad range of methodological tools, including behavioral experiments, computational modeling, fMRI, pupillometry, naturalistic paradigms and network analyses. By combining different tools and perspectives, I seek to characterize motivational influences on human cognition at the psychological, computational and neural levels. One ultimate goal of this work is to identify behavioral and neural targets of intervention to improve socio-cognitive functioning.\n","date":1507161600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1507161600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ycleong.github.io/author/yuan-chang-leong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuan-chang-leong/","section":"authors","summary":"I will be starting as an Assistant Professor at the Department of Psychology at the University of Chicago in July 2021. I am looking to hire a lab manager to start with me.","tags":null,"title":"Yuan Chang Leong","type":"authors"},{"authors":["Yuan Chang Leong","Roma Dziembaj","Mark D'Esposito"],"categories":null,"content":"","date":1612051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612051200,"objectID":"d7bd1725327e16195b86d6bf0c78e5da","permalink":"https://ycleong.github.io/publication/pupil2020/","publishdate":"2021-01-31T00:00:00Z","relpermalink":"/publication/pupil2020/","section":"publication","summary":"*Psychological Science* (accepted)","tags":null,"title":"Pupil-linked arousal biases evidence accumulation towards desirable percepts during perceptual decision-making","type":"publication"},{"authors":null,"categories":null,"content":"Individuals with different motivations often report seeing the same image differently, but it has long been disputed whether this reflects a bias in what they see or what they report seeing. Can people with diverse goals and motives truly perceive the same visual stimuli differently? I re-examined this decades-old problem using computational modeling and fMRI [1]. I measured the neural responses of participants as they viewed visually ambiguous images created by morphing together a face and a scene. Participants were rewarded for correctly judging whether the image contained ‘more face’ or ‘more scene’. For each image, I motivated them to see one of the categories by instructing them that they would earn a bonus if the image contained more of that category.\nParticipants were more likely to report seeing the image as containing more of the category they were motivated to see. If motivation altered perceptual experience, we would expect to observe a corresponding effect on neural representations in visual areas of the brain. Indeed, for a given image, face-related neural activity was higher when participants were motivated to see more face, while scene-related activity was higher when they were motivated to see more scene. Motivationally biased judgments were associated with increased activity in frontoparietal regions that I had previously found to be involved in the dynamic control of attention [2], suggesting a potential source of top-down signals driving these effects.\nAnalyzing participants’ behavior using a computational model of the underlying decision processes, I further showed that participants’ motivational bias could be decomposed into an a priori bias to respond in a motivation-consistent manner (i.e. a ‘response’ bias), as well as a bias in the accumulation of sensory information (i.e. a ‘perceptual’ bias). The response bias was associated with anticipatory activity in the nucleus accumbens, a striatal structure implicated in reward processing and action selection. In contrast, the perceptual bias tracked modulations in category-selective neural activity in the visual cortex.\nReframing the problem as a ‘how’ question opens the door to new lines of enquiry about mechanisms. Drawing on the intuition that motivation tends to be arousing, as well as prior work showing that arousal tunes visual attention, I hypothesized that motivational effects on perception are mediated by changes in physiological arousal. In my postdoctoral work, I show that heightened arousal, as measured using pupillometry, was indeed associated with motivational biases in the accumulation of perceptual information [3]. Ongoing and future work further explores this topic by examining the temporal dynamics of motivational biases, the neural mechanisms that mediate arousal effects, and the different effects of approach and avoidance motivations. In bringing together a formal characterization of behavior, affective states and brain function, this work seeks to advance an integrative understanding of motivated visual perception.\nMedia:\nHow desire can warp our view of the world (Vox, 8.8.2019)\nWhy we see what we want to see (Psychology Today, 7.9.2019)\nIs visual representation coloured by desire? (News and Views, Nature Human Beahvior, 7.1.2019)\nReferences:\n  Leong, Y. C., Hughes, B. L., Wang, Y., \u0026amp; Zaki, J. Neurocomputational mechanisms underlying motivated seeing. Nature Human Behaviour, 3(9): 962-973 (2019)\n  Leong, Y. C.*, Radulescu, A.*, Daniel, R., DeWoskin, V., \u0026amp; Niv, Y. Dynamic interaction between reinforcement learning and attention in multidimensional environments. Neuron, 93(2): 451-463 (2017)\n  Leong, Y. C., Dziembaj, R. \u0026amp; D\u0026rsquo;Esposito, M. Pupil-linked arousal biases evidence accumulation towards desirable percepts during perceptual decision-making. bioRxiv (2020)\n  ","date":1601856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601856000,"objectID":"1b552f758c5238653bdb7599504e4bce","permalink":"https://ycleong.github.io/project/a_visualperception/","publishdate":"2020-10-05T00:00:00Z","relpermalink":"/project/a_visualperception/","section":"project","summary":"Individuals with different motivations often report seeing the same image differently, but it is unclear whether this reflects a bias in what they *see* or what they *report* seeing. Can people with diverse goals and motives truly perceive the same visual stimuli differently? In recent work, I combined computational modeling and fMRI to provide a neurocomputational account of how motivation biases visual perception.","tags":null,"title":"Motivated visual perception","type":"project"},{"authors":null,"categories":null,"content":"Biased assimilation of information drives increasing political polarization – the same event, perceived differently by conservatives and liberals, cause both groups to become more entrenched in their beliefs. The consequences of biased perceptions on attitude polarization are well-documented, but it remains unclear how exactly political information is perceived differently. Do the differences emerge as a result of biases in sensory attention, in that people attend more to information supporting their beliefs, or do they reflect differences in interpreting the same sensory input? What type of content drives polarization? I sought to address these questions by combining neuroimaging and semantic analyses of real-world political messages [1].\nI measured the neural response of conservative and liberal participants watching news clips, campaign ads and political speeches related to immigration policy. I then searched the brain for neural responses that diverged between conservatives and liberals. If motivation biased sensory attention, we would expect differences in neural responses to emerge in sensory areas. Alternatively, if motivation biases the interpretation of the same sensory input, the differences would emerge only in higher-order brain areas. Consistent with the latter hypothesis, I found that the neural responses of conservative and liberal participants diverged only in the dorsomedial prefrontal cortex (DMPFC), a brain region previously shown to track the interpretation of narratives. Furthermore, the degree to which a participant’s DMPFC response was similar to that of the average conservative or average liberal participant predicted subsequent attitude change towards conservative or liberal positions respectively, suggesting that adopting an interpretation closer to a particular group biased attitudes towards positions held by that group.\nA challenge faced by prior work is that it is often difficult to precisely assess how the interpretation of two individuals differ based on their verbal reports or behavioral ratings. My approach side-steps this limitation by computing the divergence in DMPFC activity between conservative and liberal participants at each timepoint as a continuous and temporally resolved neural measure of divergent interpretations. The richness of the real-world stimuli used in the study then made it possible to take a data-driven approach to investigate the relationships between message content and biased processing. I broke down the content of the videos into 50 semantic categories and showed that the divergence in DMPFC activity was stronger during moments in the videos with moral-emotional and threat-related language, highlighting the content features most likely to drive divergent interpretations. Future work will combine neuroimaging data with sentence-embedding methods from natural language processing to build more sophisticated and specific semantic models of how political content is interpreted, with the goal of informing interventions aimed at aligning interpretations between conservatives and liberals.\nMedia:\nHot-button words trigger conservatives and liberals differently (Berkeley News, 10.20.2020)\nPolitical Views Bias Information Processing in the Brain (BrainPost, 10.27.2020)\nBrain Imaging Reveals a Neural Basis for Partisan Politics (Medscape Medical News, 10.27.2020)\nReferences:\n Leong, Y. C., Chen, J., Willer, R., \u0026amp; Zaki, J. Conservative and liberal attitudes drive polarized neural responses to political content. Proceedings of the National Academy of Sciences (in press)  ","date":1601769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601769600,"objectID":"9014b7d19778ffd1211d10a5ff3113ac","permalink":"https://ycleong.github.io/project/b_politics/","publishdate":"2020-10-04T00:00:00Z","relpermalink":"/project/b_politics/","section":"project","summary":"When presented with the identical political content, conservatives and liberals tend to interpret information in a manner that supports their existing beliefs. These biases contribute to increasing ideological polarization in America. What psychological and neural processes drive the divergent processing of political information? To address this question, we employed a novel multimethod approach that combines fMRI with semantic analyses of naturalistic political content.","tags":null,"title":"Motivated political reasoning","type":"project"},{"authors":null,"categories":null,"content":"People are motivated to seek out socially valued individuals (i.e. people who are trustworthy, supportive and well-connected), but it is unclear how efficiently and accurately they do so in real-world settings. I used a combination of social network analysis and neuroimaging to test the possibility that – even absent explicit instructions – people accurately track the social value of others in their community [1]. Socially valued individuals in two dormitories were identified from the nominations of dorm residents. I then scanned the students as they passively viewed photos of their dorm-mates. I found that brain activity in regions associated with mentalizing and value computation differentiated between viewing high valued, versus less valued peers, suggesting that people spontaneously and accurately monitor peers’ social value, potentially to guide subsequent social interactions.\nWhat happens when expectations of social value are misinformed, for example, when someone is less trustworthy than his or her reputation suggests? Will people quickly adjust their impressions, or will they perseverate on their initial expectations? In a series of behavioral studies, I show that having overly optimistic expectations about an interaction partner blinds participants to the failures of said partner in an advice-taking task, resulting in participants continuing to trust the partner’s advice despite repeated feedback that the advice is inaccurate [2]. Together, this line of work parallels my other work on visual perception and demonstrates how social value biases representations of the social world.\nReferences:\n  Morelli, S. A.*, Leong, Y. C.*, Carlson, R. W., Kullar, M., \u0026amp; Zaki, J. Neural detection of socially valued community members. Proceedings of the National Academy of Sciences, 115(32): 8149-8154 (2018)\n  Leong, Y. C. \u0026amp; Zaki, J. Unrealistic optimism in advice taking: A computational account. Journal of Experimental Psychology: General, 147(2): 170 (2018)\n  ","date":1601683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601683200,"objectID":"5681a90e108b0f8d5dc4d55fe4f23e2c","permalink":"https://ycleong.github.io/project/c_socialperception/","publishdate":"2020-10-03T00:00:00Z","relpermalink":"/project/c_socialperception/","section":"project","summary":"People are motivated to seek out socially valued individuals in their community (i.e. people who are trustworthy, supportive and well-connected). How do people identify these individuals? What happens when expectations of social value are misinformed, for example, when someone is less trustworthy than their reputation suggests? In this line of work, I use fMRI, social network analyses and computational modeling to examine how social value guides social interactions.","tags":null,"title":"Motivated social perception","type":"project"},{"authors":null,"categories":null,"content":"A (beautiful) feature of human experience is that we don\u0026rsquo;t have to experience everything ourselves. Through the stories we tell one another, we can, to a degree, experience the life of another.\nIn work with collaborators, I have explored the neural underpinnings of how people talk to and understand each other. We scanned participants watching a 50-minute movie clip and talking about the plot immediately afterwards. We show that watching and talking about the same scene elicits a similar pattern of neural activity. The pattern was also shared across people talking about the same scene, revealing the existence of a common \u0026lsquo;neural code\u0026rsquo; that could serve as the foundation for human communication [1].\nIn a second study, we scanned a group of participants who had not watched the movie as they listened to someone talking about the movie. We found that listening to the speaker talk about a scene elicited a pattern of neural activity that was similar to that of the speaker watching that scene, despite participants not having seen the movie themselves [2]. Together, these results suggest that communication is associated with the construction and transmission of shared neural representations.\nReferences:\n  Chen, J.*, Leong, Y. C.*, Honey, C. J., Yong, C. H., Norman, K. A., \u0026amp; Hasson, U. Shared memories reveal shared structure in neural activity across individuals. Nature Neuroscience, 20(1): 8149-8154 (2017)\n  Zadbood, A., Chen, J., Leong, Y. C., Norman, K. A., \u0026amp; Hasson, U. How we transmit memories to other brains: constructing shared neural representations via communication. Cerebral Cortex, 27(10): 4988-5000 (2017)\n  ","date":1601596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601596800,"objectID":"eb137b0c5c31e5fc86e07e39bcee882e","permalink":"https://ycleong.github.io/project/d_communication/","publishdate":"2020-10-02T00:00:00Z","relpermalink":"/project/d_communication/","section":"project","summary":"In a separate line of work, my collaborators and I have studied the neural bases of human communication. We found that (1) experiencing, (2) talking about and (3) listening to a verbal description of an event elicits shared patterns of neural activity across individuals. The fidelity of this neural pattern correlated with communication success. These results suggest that communication is associated with the construction of shared neural representations.","tags":null,"title":"Communication and shared experiences","type":"project"},{"authors":["Sameul Nastase","Yun-Fei Liu","Hanna Hillman","Asieh Zadbood","Liat Hasenfratz","Neggin Keshavarzian","Janice Chen","Christopher J. Honey","Yaara Yeshurun","Mor Regev","Mai Nguyen","Claire H.C. Chang","Christopher Baldassano","Olga Lositsky","Erez Simony","Michael A. Chow","Yuan Chang Leong","Paula P. Brooks","Emily Micciche","Gina Choe","Ariel Goldstein","Tamara Vanderwal","Yaroslav O. Halchenko","Kenneth A. Norman"],"categories":null,"content":"","date":1580428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580428800,"objectID":"4823d3e2b1b54883ce7edeeb8eb217aa","permalink":"https://ycleong.github.io/publication/nastase2020/","publishdate":"2020-01-31T00:00:00Z","relpermalink":"/publication/nastase2020/","section":"publication","summary":"*bioRxiv* (2020)","tags":null,"title":"Narratives: fMRI data for evaluating models of naturalistic language comprehension","type":"publication"},{"authors":["Yuan Chang Leong","Janice Chen","Robb Willer","Jamil Zaki"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"cb9c939e7a01e9887d9dfd2882bb394a","permalink":"https://ycleong.github.io/publication/pnas2020/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/pnas2020/","section":"publication","summary":"*Proceedings of the National Academy of Sciences* (2021)","tags":null,"title":"Conservative and liberal attitudes drive polarized neural responses to political content","type":"publication"},{"authors":["Yuan Chang Leong","Brent L Hughes","Yiyu Wang","Jamil Zaki"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"cffdd6d368538aa98fc7609dbc1298ed","permalink":"https://ycleong.github.io/publication/nhb2019/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/nhb2019/","section":"publication","summary":"*Nature Human Behavior* (2019)","tags":null,"title":"Neurocomputational mechanisms underlying motivated seeing","type":"publication"},{"authors":["Yuan Chang Leong","Jamil Zaki"],"categories":null,"content":"","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"aeb73f1de18f560d3512bee03d393a4a","permalink":"https://ycleong.github.io/publication/jpeg2019/","publishdate":"2018-02-01T00:00:00Z","relpermalink":"/publication/jpeg2019/","section":"publication","summary":"*Journal of Experimental Psychology: General* (2018)","tags":null,"title":"Unrealistic optimism in advice taking: A computational account","type":"publication"},{"authors":["Sylvia Morelli","Yuan Chang Leong","Ryan Carlson","Monica Kullar","Jamil Zaki"],"categories":null,"content":"","date":1515283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515283200,"objectID":"71fb0492c081c8e0a124545b4e8c0226","permalink":"https://ycleong.github.io/publication/pnas2019/","publishdate":"2018-08-07T00:00:00Z","relpermalink":"/publication/pnas2019/","section":"publication","summary":"*Proceedings of the Academy of the Sciences* (2018)","tags":null,"title":"Neural detection of socially valued community members","type":"publication"},{"authors":["Yuan Chang Leong","Angela Radulescu","Reka Daniel","Vivian DeWoskin","Yael Niv"],"categories":null,"content":"","date":1513555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513555200,"objectID":"8a156f5a7a9e1a8878a5ea361f599d07","permalink":"https://ycleong.github.io/publication/neuron2017/","publishdate":"2017-12-18T00:00:00Z","relpermalink":"/publication/neuron2017/","section":"publication","summary":"*Neuron* (2017)","tags":null,"title":"Dynamic interaction between reinforcement learning and attention in multidimensional environments","type":"publication"},{"authors":["Asieh Zadbood","Janice Chen","Yuan Chang Leong","Kenneth A Norman","Uri Hasson"],"categories":null,"content":"","date":1507161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507161600,"objectID":"e2a3af91755f468dd065c1b5083c1703","permalink":"https://ycleong.github.io/publication/cerebcortex2017/","publishdate":"2017-10-05T00:00:00Z","relpermalink":"/publication/cerebcortex2017/","section":"publication","summary":"*Cerebral Cortex* (2017)","tags":null,"title":"How we transmit memories to other brains: Constructing shared neural representations via communication","type":"publication"},{"authors":["Janice Chen","Yuan Chang Leong","Christopher J Honey","Chung H Yong","Kenneth A Norman","Uri Hasson"],"categories":null,"content":"","date":1504569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504569600,"objectID":"15cb00d62ed58cf3d7ae849917ba925a","permalink":"https://ycleong.github.io/publication/natneu2017/","publishdate":"2017-09-05T00:00:00Z","relpermalink":"/publication/natneu2017/","section":"publication","summary":"*Nature Neuroscience* (2017)","tags":null,"title":"Shared memories reveal shared structure in neural activity across individuals","type":"publication"},{"authors":["Natalia Velez","Yuan Chang Leong","Chelsey Pan","Hyowon Gweon"],"categories":null,"content":"","date":1451952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451952000,"objectID":"0767e68075ab43be7abff4dd544b9f16","permalink":"https://ycleong.github.io/publication/cogsci_2016/","publishdate":"2016-01-05T00:00:00Z","relpermalink":"/publication/cogsci_2016/","section":"publication","summary":"*Proceedings of the 38th Annual Conference of the Cognitive Science Society* (2016)","tags":null,"title":"Learning and making novel predictions about others' preferences","type":"publication"},{"authors":["Yael Niv","Reka Daniel","Andra Geana","Samuel J Gershman","Yuan Chang Leong","Angela Radulescu","Robert C Wilson"],"categories":null,"content":"","date":1432684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1432684800,"objectID":"6965a8371e4c9fc3b348dc9293d1da5b","permalink":"https://ycleong.github.io/publication/jneuro2015/","publishdate":"2015-05-27T00:00:00Z","relpermalink":"/publication/jneuro2015/","section":"publication","summary":"*Journal of Neuroscience* (2015)","tags":null,"title":"Reinforcement learning in multidimensional environments relies on attention mechanisms","type":"publication"},{"authors":["Yuan Chang Leong","Yael Niv"],"categories":null,"content":"","date":1357344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1357344000,"objectID":"a80722357fc77e2a3b31d51ba4dd56e1","permalink":"https://ycleong.github.io/publication/rldm_2013/","publishdate":"2013-01-05T00:00:00Z","relpermalink":"/publication/rldm_2013/","section":"publication","summary":"*1st Multidisciplinary Conference on Reinforcement Learning and Decision Making* (2013)","tags":null,"title":"Human reinforcement learning processes act on learned attentionally-filtered representations of the world","type":"publication"},{"authors":["Philip Johnson-Laird","Olivia E Kang","Yuan Chang Leong"],"categories":null,"content":"","date":1346457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1346457600,"objectID":"e3f302014bfdd3025ae88a1cceb49b75","permalink":"https://ycleong.github.io/publication/music2012/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/music2012/","section":"publication","summary":"*Music Perception* (2012)","tags":null,"title":"On musical dissonance","type":"publication"}]